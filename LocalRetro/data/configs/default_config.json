{
  "attention_heads": 8,
  "attention_layers": 1,
  "batch_size": 16,
  "edge_hidden_feats": 64,
  "node_out_feats": 320,
  "num_step_message_passing": 6,
  "activation": "gelu"
}